##Protokoll 13.05. 

Protokollant 1:  Johannes
Protokollant 2:  Julia

### Kurzer Standup
Probleme:
 - Problem der Nutzerperspektive :)

### Bericht aus den Teams
####Team: Organisation - Github (Keno, Adriana)
   - Wiki Page Development tools
   - 6 core practices mit Tools:
   - miro == gather requirements & do brainstorming
   - github board == organize the activities (like a kanban board)
   - github review management system == reports issues (e.g. at PR)
   - Github scanning == code quality + bug finding
   - Grafana == monitoring
   - Kibana == sammeln von logs
   - application testing framework == ?
   - docker == create containerized applications
   - GitHub actions == bug tracing (like Travis CI)
   - Worklflow
   - arbeiten mit feature branches 
   - direkter push auf den master branch ist ein no go --> ggf. wird master vor direkt pushes geschützt --> nur via pull requests (PR) möglich
   - commit message convention
   - Jede Arbeit wird als Issue getrackt
   - scope und abschluss kriterien
   - je nach Aufwand des Issues werden "T-Shirt-Größen" je Issue vergeben --> je größer das Shirt, desto größer der Aufwand in Stunden
   - neue bounty immer mit Readme anlegen und zum bounty board hinzufügen
   - Bearbeiter schließen Issue mit pull request ab -> review anfragen
   - Review von jemanden  der Issue nicht bearbeitet hat  
   - **Next Steps** 
        - code of conduct hinzufügen, der dem Berlin CoC folgt
        - Wiki Organisation --> Wie kann History getrakct werden? // Wie könnte eine inhaltlich Struktur aussehen? (pull requests nicht )
        - Discord-Channel anlegen https://discord.com/invite/RaN4PZ

> Nice to know: Schätzung des Issue-Aufwands basiert auf Fibonacci-Reihe

**Fragen/Anmerkungen:**
    - wie kann das Wiki umorganisert werden, damit die Inhalte direkter zugreifbar sind?
    - Wir haben eine Sketch Lizenz, wenn Interesse besteht.
    - Wie werden in dem Board die unterschiedlichen Aktivitäten der einzelnen Teams organisiert?
    - Soll der Master branch protected werden?
    - Warum werden Issues (Bounties) zeitlich so geschätzt, wie sie geschätzt werden?
    - Sollen Reviewer definiert werden?


####Team: Github Pages (Di Wang, Tung Duong, Oussama Bouanani, Omer Hod)
   - Nutzung von React (JavaScript Framework)
   - Programmierung mit Javascript anstatt Type Script
   - Facebooks create-app
   - neue branch == "project-website"
   - für deploy: Nutzung von npm (node package manager) scripts
   - https://fub-hcc.github.io/20-SWP-CodingOpenness/
   - **Next Steps:** 
        - Anlegen der Templates für:
        - Vision des Projektes
        - beschreibung des Projektkontexts
        - Teammitglieder
        - andere content-sites



####Team: Technik (Julius Brose, Johannes, Pascal, Dennis, Long Dang)
   - im Issue sind Informationen zu weiterführenden Kursen hinterlegt
   - Kotlin und Java Kurse
   - bevorzugte IDE: [android studio](https://developer.android.com/studio/intro)
   - https://www.thecrazyprogrammer.com/learn-android-programming
   - [Kotlin Koans](https://play.kotlinlang.org/koans/overview)
   - **Next Steps:**
        - Essenz der Diskussion (im Issue) auf eine Page packen


####Team: Vergleich der Ansätze (Claas Fandre, Julia Zimmermann, Linus Helfmann, Bernd Sahre, Viktoriya Kraleva)
   - Wiki-Page angelegt : https://github.com/FUB-HCC/20-SWP-CodingOpenness/wiki/Vergleich-der-Ans%C3%A4tze
   - Unterteiwlung aller Kriterien in 3 große Themenbereiche:
   - Vergleich nach Architektur
   - zentral / dezantral
   - ort der Speicherung der Ids
   - Ort der Berechnung
   - Verfahren zur Aktualisierung
   - vergleich Kommunikationsablauf:
   - Push/ poll
   - Verschlüsselung
   - etc.
   - Vergleich Privatsphäre un Transparenz
   - Technisch und nicht-technisch
   - wie lange werden Daten gespeichert
   - wer entscheidet über Datenübertragung

Frage: Wer ist unsere Zielgruppe?
    - Kurzfristig: unsere Projektgruppe
    - Langfristig: evtl. etwas niedrigschwelliger
    - Woher kommen die detaillierten Texte? Sind das Zitate aus den Originaltexten?


Open Call für weitere Kriterien: 
    - Wem noch Kriterien einfallen, kann diese gerne ins Issue schreiben

    
**TO DO für alle:**  Vergleich der Ansätze anschauen und ggf. Fragen notieren
    
**Next Steps:**
 - Herrn Marian Margraf  konsultieren und Ergebnisse zu "Privatsphäre" abgleichen/erweitern
 - ggf. Herrn Gerhard Wunder zum Thema BLE konsultieren

####Team: Fragebogen (Ingrid Tchilibou, Felix Sekul, David Paulini, Torben Knaak)
   - Problem und Ziel identifiziert
   - ableitend davon: 12 Fragen formuliert
   - Tools: Googleforms & Limesurvey
   - Fragebogen mit Limesurvey erstellt


Anmerkungen:
    - Hilfe bei LimeSurvey
    - Fragen prüfen
    - evtl. in drei Nutzergruppen (anhand des vorhandenen Wissens) unterteilen:
    - Personen, die die App nicht nutzen/kennen
    - Personen, die schon mal davon gehört habeb
    - "early-adopters", die schon sehr gut informiert sind und rege an der Diskussion teilnehemen
            

**Next steps:**
  - Fragen in Google Forms übertragen
  - Fragbogen an Freunde/ Familie verteilen
  - Fragebogen in Wikiseite übertragen
  - Evtl. besser https://www.typeform.com/ nutzen statt Google Forms
    
Hinweis: Bernd und Julia vom Team "Vergleich" sind ins Team "Fragebogen" gewechselt (temporär)


### Weiteres Vorgehen
**TODO Für alle:**   
https://www.fu-berlin.de/campusleben/forschen/2020/200512-corona-interview-mueller-birn/index.html
lesen

**Team GitHub Pages & Technik:**
   - Dokumentation 
   - Website aufsetzen und befüllen
    
**Team "Fragebogen" Deadline bis Montag:**
   - Fragebogen fertigstellen
